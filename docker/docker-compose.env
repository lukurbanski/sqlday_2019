# https://spark.apache.org/docs/latest/spark-standalone.html
#HDFS_NAMENODE_PORT=8020
#HDFS_NAMENODE_HOSTNAME=spark-master

# Default Hadoop filesystem
#HDFS_DEFAULT_FS=hdfs://hadoop-namenode:8020
HDFS_DEFAULT_FS=

SPARK_MASTER_HOST=spark-master
SPARK_MASTER_PORT=7077
#SPARK_WORKER_INSTANCES=2

#SPARK_WEBUI_PORT=9090
#SPARK_PUBLIC_DNS=localhost

SPARK_WORKER_CORES=2
#SPARK_WORKER_MEMORY=4G
SPARK_WORKER_MEMORY=6G
SPARK_LOCAL_DIRS=/tmp
SPARK_WORKER_DIR=/tmp

# Additional Spark variables used by notebook
#SPARK_DRIVER_MEMORY=2G
#SPARK_EXECUTOR_MEMORY=4G
#SPARK_EXECUTOR_CORES=2
#SPARK_NUM_EXECUTORS=2

SPARK_DRIVER_MEMORY=4G
SPARK_EXECUTOR_MEMORY=6G
SPARK_EXECUTOR_CORES=2
SPARK_NUM_EXECUTORS=2

# AWS S3 Configuration
S3_ENDPOINT=s3.eu-central-1.amazonaws.com
#S3_PROXY_HOST=<your-proxy-host>
#S3_PROXY_PORT=<your-proxy-port>

#AWS_ACCESS_KEY_ID=tutaj możesz wpisać swój AWS S3 KEY
#AWS_SECRET_ACCESS_KEY=uzupełnij dane...
